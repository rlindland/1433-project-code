{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRAPES AD DATA\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_info():\n",
    "    #def fetch_from_538(state):\n",
    "    forecast_page = \"https://projects.fivethirtyeight.com/2020-campaign-ads/#\"\n",
    "    forecast_html = requests.get(forecast_page)\n",
    "    soup = BeautifulSoup(forecast_html.text, 'html.parser')\n",
    "    # soup.prettify()\n",
    "    options = list(soup.find_all('option'))\n",
    "    #options[0].split(\"\\\"\")\n",
    "    options = [str(i).split(\"\\\"\")[1] for i in options]\n",
    "    split = len(options)-51\n",
    "    candidates = [i.lower().replace(\" \",\"-\") for i in options if \" \" in i]\n",
    "    states = [i.lower() for i in options if \" \" not in i and i!=\"\" and i!=\"National\"]\n",
    "    assert len(states)+len(candidates)==len(options)-3\n",
    "    \n",
    "    for i in range(len(candidates)): \n",
    "        if candidates[i]=='juliÃ¡n-castro':\n",
    "            candidates[i]='julin-castro'\n",
    "    return states, candidates\n",
    "\n",
    "\n",
    "def to_df(name_l, state_l, airings_l, start_l, end_l, cost_l, title_l, lookup_l, issues_l):\n",
    "    out = pd.DataFrame(data = {\"candidate\":name_l, \"state\":state_l, \"airings\":airings_l, \"start\":start_l, \"end\":end_l, \"cost\":cost_l, \"title\":title_l, \"lookup\":lookup_l, \"issues\":issues_l})\n",
    "    return out\n",
    "\n",
    "def parse2(text, starts, ends):\n",
    "    \n",
    "    months = [\"jan\", \"feb\", \"march\", \"april\", \"may\", \"june\", \"july\", \"aug\", \"sept\", \"oct\", \"nov\", \"dec\"]\n",
    "\n",
    "    month_map = {}\n",
    "    for i in range(len(months)):\n",
    "        month_map[months[i]]=str(i+1)\n",
    "    \n",
    "    words = text.lower().split(\" \")\n",
    "    \n",
    "    if len(words)==11:\n",
    "        start_month = month_map[words[4].lower().replace(\".\",\"\")]\n",
    "        if len(start_month)==1: start_month = \"0\"+start_month\n",
    "        start_day = words[5].replace(\",\",\"\")\n",
    "        if len(start_day)==1: start_day = \"0\"+start_day\n",
    "        start_year = words[6]\n",
    "        start_date = start_year+start_month+start_day\n",
    "        starts.append(start_date)\n",
    "\n",
    "        end_month = month_map[words[8].lower().replace(\".\",\"\")]\n",
    "        if len(end_month)==1: end_month = \"0\"+end_month\n",
    "        end_day = words[9].replace(\",\",\"\")\n",
    "        if len(end_day)==1: end_day = \"0\"+end_day\n",
    "        end_year = words[10]\n",
    "        end_date = end_year+end_month+end_day\n",
    "        ends.append(end_date)\n",
    "    \n",
    "    elif len(words)==9:\n",
    "        start_month = month_map[words[4].lower().replace(\".\",\"\")]\n",
    "        if len(start_month)==1: start_month = \"0\"+start_month\n",
    "        start_day = words[5].replace(\",\",\"\")\n",
    "        if len(start_day)==1: start_day = \"0\"+start_day\n",
    "        start_year = \"2020\"\n",
    "        start_date = start_year+start_month+start_day\n",
    "        starts.append(start_date)\n",
    "\n",
    "        end_month = month_map[words[7].lower().replace(\".\",\"\")]\n",
    "        if len(end_month)==1: end_month = \"0\"+end_month\n",
    "        end_day = words[8].replace(\",\",\"\")\n",
    "        if len(end_day)==1: end_day = \"0\"+end_day\n",
    "        end_year = \"2020\"\n",
    "        end_date = end_year+end_month+end_day\n",
    "        ends.append(end_date)\n",
    "        \n",
    "    elif len(words)==6:\n",
    "        start_month = month_map[words[4].lower().replace(\".\",\"\")]\n",
    "        if len(start_month)==1: start_month = \"0\"+start_month\n",
    "        start_day = words[5].replace(\",\",\"\")\n",
    "        if len(start_day)==1: start_day = \"0\"+start_day\n",
    "        start_year = \"2020\"\n",
    "        start_date = start_year+start_month+start_day\n",
    "        starts.append(start_date)\n",
    "        ends.append(start_date)\n",
    "        \n",
    "    elif len(words)==7:\n",
    "        start_month = month_map[words[4].lower().replace(\".\",\"\")]\n",
    "        if len(start_month)==1: start_month = \"0\"+start_month\n",
    "        start_day = words[5].replace(\",\",\"\")\n",
    "        if len(start_day)==1: start_day = \"0\"+start_day\n",
    "        start_year = \"2019\"\n",
    "        start_date = start_year+start_month+start_day\n",
    "        starts.append(start_date)\n",
    "        ends.append(start_date)\n",
    "        \n",
    "    elif len(words)==10:\n",
    "        start_month = month_map[words[4].lower().replace(\".\",\"\")]\n",
    "        if len(start_month)==1: start_month = \"0\"+start_month\n",
    "        start_day = words[5].replace(\",\",\"\")\n",
    "        if len(start_day)==1: start_day = \"0\"+start_day\n",
    "        start_year = words[6]\n",
    "        start_date = start_year+start_month+start_day\n",
    "        starts.append(start_date)\n",
    "\n",
    "        end_month = month_map[words[8].lower().replace(\".\",\"\")]\n",
    "        if len(end_month)==1: end_month = \"0\"+end_month\n",
    "        end_day = words[9].replace(\",\",\"\")\n",
    "        if len(end_day)==1: end_day = \"0\"+end_day\n",
    "        end_year = \"2020\"\n",
    "        end_date = end_year+end_month+end_day\n",
    "        ends.append(end_date)\n",
    "        \n",
    "    else:\n",
    "        print(words)\n",
    "        assert False\n",
    "\n",
    "def scrape_ads(fileout=\"./tvads.csv\"):\n",
    "    name_l = []\n",
    "    state_l = []\n",
    "    airings_l = []\n",
    "    start_l = []\n",
    "    end_l = []\n",
    "    cost_l = []\n",
    "    title_l = []\n",
    "    lookup_l = []\n",
    "    issues_l = []\n",
    "\n",
    "    titles = set()\n",
    "\n",
    "    states, candidates = get_info()\n",
    "\n",
    "\n",
    "    chrome_path = \"./chromedriver\"\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path)\n",
    "\n",
    "    for state in states:\n",
    "        for name in candidates:\n",
    "            driver.get(\"https://projects.fivethirtyeight.com/2020-campaign-ads/#candidate=\"+name+\"&market=\"+state)\n",
    "            posts = driver.find_elements_by_class_name(\"ad\")\n",
    "            d = driver.find_elements_by_class_name(\"date\")\n",
    "\n",
    "            d = [d[i] for i in range(len(d)) if len(d[i].text)>0]\n",
    "\n",
    "\n",
    "\n",
    "            if len(d) != len(posts):\n",
    "                print(\"-----\",name,state)\n",
    "                assert False\n",
    "\n",
    "\n",
    "            else:\n",
    "                for j in range(len(posts)):\n",
    "                    post = posts[j]\n",
    "\n",
    "                    #print(post.text)\n",
    "                    title = post.find_elements_by_class_name(\"title\")[0].text\n",
    "                    if title not in titles:\n",
    "                        titles.add(title)\n",
    "                        locs = post.find_elements_by_tag_name(\"table\")[0].find_elements_by_tag_name(\"tbody\")[0].find_elements_by_tag_name(\"tr\")\n",
    "                        for i in locs: \n",
    "                            tokens = i.text.split(\" \")\n",
    "                            if len(tokens)==4:\n",
    "                                tokens[1]=tokens[0]+\" \"+tokens[1]\n",
    "                                tokens=tokens[1:]\n",
    "                            if len(tokens)!=3:\n",
    "                                print(tokens)\n",
    "                                assert False \n",
    "                            statea = tokens[0]\n",
    "                            airings = int(tokens[1].replace(\",\",\"\"))\n",
    "                            cost = int(tokens[2][1:].replace(\",\",\"\"))\n",
    "                            \n",
    "                            issues = post.find_elements_by_class_name(\"issues\")\n",
    "                            if len(issues)==0:\n",
    "                                print(\"F:\", name,state,title)\n",
    "                            issues = issues[0].text\n",
    "                            \n",
    "        \n",
    "                            name_l.append(name)\n",
    "                            lookup_l.append(state)\n",
    "                            state_l.append(statea)\n",
    "                            airings_l.append(airings)\n",
    "                            cost_l.append(cost)\n",
    "                            title_l.append(title)\n",
    "                            issues_l.append(issues)\n",
    "                            \n",
    "                            parse2(d[j].text, start_l, end_l)        \n",
    "                            #print(cost, airings, state)\n",
    "            out = to_df(name_l, state_l, airings_l, start_l, end_l, cost_l, title_l, lookup_l, issues_l)\n",
    "            print(out)\n",
    "            out.to_csv(fileout)\n",
    "            #print(post.find_elements_by_class_name(\"main\")[0].find_elements_by_class_name(\"markets\")[0].find_elements_by_class_name(\"market text\"))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_ads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT DATA\n",
    "def fix_date(df):\n",
    "    def to_ymd(x):\n",
    "        toks = x.split(\"/\")\n",
    "        for i in range(len(toks)):\n",
    "            if len(toks[i])==1:\n",
    "                toks[i]=\"0\"+toks[i]\n",
    "        return int(toks[2]+toks[0]+toks[1])\n",
    "\n",
    "    df[\"date\"] = df.modeldate.apply(to_ymd)\n",
    "\n",
    "def make_names(df):      \n",
    "    def get_short_name(x):\n",
    "        if x == 'Joseph R. Biden Jr.': cand = \"joe-biden\"\n",
    "        elif x == 'Bernard Sanders': cand = \"bernie-sanders\"\n",
    "        else:\n",
    "            name = x.split(\" \")\n",
    "            cand = name[0].lower()+\"-\"+name[-1].lower()\n",
    "        return cand\n",
    "    df[\"cand\"]=df.candidate_name.apply(get_short_name)\n",
    "    \n",
    "    \n",
    "def get_poll_diffs():\n",
    "    polls = pd.read_csv(\"~/Downloads/polls/pres_primary_avgs_2020.csv\")\n",
    "    polls[\"pct_change\"]=np.nan\n",
    "    make_names(polls)\n",
    "    fix_date(polls)\n",
    "    \n",
    "    polls = polls.sort_values(by=[\"cand\",\"state\",\"date\"])\n",
    "    polls = polls.reset_index(drop=True)\n",
    "    \n",
    "    polls['pct_ch'] = 100*(polls.groupby([\"cand\",\"state\"])[\"pct_trend_adjusted\"]\n",
    "                                  .apply(pd.Series.pct_change))\n",
    "    \n",
    "    \n",
    "    polls[\"log\"] = np.log(polls[\"pct_trend_adjusted\"])\n",
    "    polls['log_ch'] = (polls.groupby([\"cand\",\"state\"])[\"log\"]\n",
    "                                  .apply(pd.Series.pct_change))\n",
    "    return polls\n",
    "                \n",
    "    \n",
    "def get_data(out, polls ,fileout,skip_low=False):\n",
    "    ev_time_t = []\n",
    "    state_t = []\n",
    "    cand_t = []\n",
    "    poll_t = []\n",
    "    date_t = []\n",
    "    title_t = []\n",
    "    lookup_t = []\n",
    "    raw_change_t = []\n",
    "    pct_change_t = []\n",
    "    log_change_t = []\n",
    "    daily_pct = []\n",
    "    daily_log = []\n",
    "    issues_t = []\n",
    "    airings_t = []\n",
    "    cost_t = []\n",
    "    polla_t = []\n",
    "\n",
    "    make_names(polls)\n",
    "    fix_date(polls)\n",
    "    \n",
    "    polls = polls.sort_values(by=[\"cand\",\"state\",\"date\"])\n",
    "    polls = polls.reset_index(drop=True)\n",
    "    good = 0 \n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for i in out.index:\n",
    "        counter+=1\n",
    "        if counter%300==0: \n",
    "            print(counter,\"/\",len(out))\n",
    "        cand = out.candidate[i]\n",
    "        state = out.state[i]\n",
    "        date = out.start[i]\n",
    "        title = out.title[i]\n",
    "        lookup = out[\"lookup\"][i]\n",
    "        iss = out.issues[i]\n",
    "        arng = out.airings[i]\n",
    "        cost = out.cost[i]\n",
    "\n",
    "\n",
    "\n",
    "        row = polls.loc[(polls.state==state)&(polls.cand==cand)&(polls.date==date)]\n",
    "        \n",
    "\n",
    "        if len(row)!=0:\n",
    "            polla = row.pct_trend_adjusted[row.index[0]]\n",
    "            \n",
    "            if skip_low:\n",
    "                assert len(row)==1\n",
    "                if row.pct_trend_adjusted[row.index[0]]<5:\n",
    "                    continue\n",
    "        \n",
    "            #print(\"CHECK\",cand,state,date,out[\"lookup\"][i],out[\"title\"][i])\n",
    "            ind = row.index[0]\n",
    "            lower = ind-30\n",
    "            upper = ind+30\n",
    "            \n",
    "            base = polls.iloc[ind][\"pct_trend_adjusted\"]\n",
    "\n",
    "            good+=1\n",
    "\n",
    "            for j in range(lower,upper):\n",
    "                curr = polls.iloc[j]\n",
    "                if curr[\"cand\"]==cand and curr[\"state\"]==state:\n",
    "                    ev_time_t.append(j-ind)\n",
    "                    state_t.append(state)\n",
    "                    cand_t.append(cand)\n",
    "                    poll_t.append(curr.pct_trend_adjusted)\n",
    "                    date_t.append(curr[\"date\"])\n",
    "                    title_t.append(title)\n",
    "                    lookup_t.append(lookup)\n",
    "                    raw_change_t.append(curr.pct_trend_adjusted-base)\n",
    "                    pct_change_t.append((curr.pct_trend_adjusted-base)/base)\n",
    "                    log_change_t.append(np.log(curr.pct_trend_adjusted)-np.log(base))\n",
    "                    daily_pct.append(curr.pct_ch)\n",
    "                    issues_t.append(iss)\n",
    "                    daily_log.append(curr.log_ch)\n",
    "                    airings_t.append(arng)\n",
    "                    cost_t.append(cost)\n",
    "                    polla_t.append(polla)\n",
    "                    \n",
    "        else:\n",
    "            assert len(row)==0\n",
    "\n",
    "    data = pd.DataFrame(data = {\"ev_time\": ev_time_t, \"state\": state_t, \"cand\": cand_t, \"poll\" : poll_t, \"date\":date_t, \"title\":title_t, \"lookup\":lookup_t, \"raw_change\":raw_change_t, \"pct_change\":pct_change_t, \"log_change\":log_change_t, \"daily_pct\":daily_pct, \"daily_log\":daily_log, \"issues\":issues_t, \"airings\":airings_t, \"cost\":cost_t, \"polla\":polla_t})    \n",
    "    data.to_csv(fileout)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv(\"./tvads.csv\")\n",
    "polls = get_poll_diffs()\n",
    "data = get_data(out, polls, \"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD FEATURE COLUMNS\n",
    "def quantiles(data,n=5,pref=\"q\"):\n",
    "    qs = [round(1/n*i*100) for i in range(n+1)]\n",
    "    print(qs)\n",
    "    for i in range(1,len(qs)):\n",
    "        lb = np.percentile(data.loc[data.polla.isnull()==False, \"polla\"],qs[i-1])\n",
    "        ub = np.percentile(data.loc[data.polla.isnull()==False, \"polla\"],qs[i])\n",
    "        print((lb,ub))\n",
    "        data[pref+\"tile_\"+str(i)]=0\n",
    "        data.loc[(data.polla>lb)&(data.polla<=ub),pref+\"tile_\"+str(i)]=1\n",
    "\n",
    "def lb(data):\n",
    "    lbs = [i for i in range(0,16,3)][1:]\n",
    "    for i in lbs:\n",
    "        data[\"lb_\"+str(i)]=0\n",
    "        data.loc[data.polla>i, \"lb_\"+str(i)]=1\n",
    "\n",
    "def candstate(data):\n",
    "    for c in data.cand.unique():\n",
    "        for s in data.state.unique():\n",
    "            data[\"candstate_\"+c+\"_\"+s]=0\n",
    "            data.loc[(data.cand==c)&(data.state==s),\"candstate_\"+c+\"_\"+s]=1\n",
    "            \n",
    "    allct = [i for i in data.columns if i[:len(\"candstate\")]==\"candstate\"]\n",
    "    dropct = [i for i in allct if len(data[i].unique())==1]\n",
    "    data = data.drop(columns = dropct)\n",
    "    return data\n",
    "\n",
    "def candtime(data):\n",
    "    hmon = [\"00\",\"15\"]\n",
    "    data = add_time_controls(data,\"hmon\",hmon)\n",
    "    hmons = [i for i in data.columns if i[:4]==\"hmon\"]\n",
    "    \n",
    "    for c in data.cand.unique():\n",
    "        for hm in hmons:\n",
    "            data[\"candtime_\"+c+\"_\"+hm]=0\n",
    "            data.loc[(data.cand==c)&(data[hm]==1),\"candtime_\"+c+\"_\"+hm]=1\n",
    "            \n",
    "    allct = [i for i in data.columns if i[:len(\"candtime\")]==\"candtime\"]\n",
    "    dropct = [i for i in allct if len(data[i].unique())==1]\n",
    "    data = data.drop(columns = dropct)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def topic_cols(data, group):\n",
    "    cols = [i for i in data.columns if i[:4]==\"iss_\"]\n",
    "    iss = [i[4:] for i in data.columns if i[:4]==\"iss_\"]\n",
    "    counts = []\n",
    "    for i in cols:\n",
    "        counts.append(data.loc[data.ev_time==0,i].sum())\n",
    "    \n",
    "    sorted_iss = sorted([(iss[i],counts[i],cols[i]) for i in range(len(iss))], key = lambda x: x[1], reverse = True)\n",
    "    iss = [i[0] for i in sorted_iss]\n",
    "    counts = [i[1] for i in sorted_iss]\n",
    "    cols = [i[2] for i in sorted_iss]\n",
    "\n",
    "    for ind in range(len(cols)):\n",
    "        for i in range(data[group].max()+1):\n",
    "            data[\"topic_\"+iss[ind]+\"_\"+str(i)]=0\n",
    "            data.loc[(data[group]==i)&(data[cols[ind]]==1),\"topic_\"+iss[ind]+\"_\"+str(i)]=1\n",
    "\n",
    "def gen_color(data):\n",
    "    el = pd.read_csv(\"elections.csv\")\n",
    "    el[\"party\"]=\"r\"\n",
    "    el.loc[el.dem>el.rep,\"party\"]=\"b\"\n",
    "    el.loc[np.abs(el.dem-el.rep)<=5,\"party\"]=\"p\"\n",
    "\n",
    "    color_map = dict([(el.iloc[i].full,el.iloc[i].party) for i in el.index])\n",
    "    color_map[\"National\"]=np.nan\n",
    "\n",
    "    data[\"color\"]=\"r\"\n",
    "    for s in data.state.unique():\n",
    "        data.loc[data.state==s,\"color\"]=color_map[s]\n",
    "\n",
    "\n",
    "def median_split(data, col):\n",
    "    med = data.loc[data.ev_time==0, col].median()\n",
    "    data[\"med_\"+col]=0\n",
    "    data.loc[data[col]>=med,\"med_\"+col]=1\n",
    "\n",
    "def make_issue_cols(data):\n",
    "    print(len(data.issues.unique()))\n",
    "    data = data.drop(data.loc[data[\"issues\"].isnull()].index)\n",
    "    issues = \";\".join(data.issues.unique()).replace(\" \",\"\").split(\";\")\n",
    "\n",
    "    issues = list(set(issues))\n",
    "\n",
    "    for i in issues:\n",
    "        data[\"iss_\"+i.lower()] = 0\n",
    "\n",
    "    for i in data.index:\n",
    "        iss = data[\"issues\"][i]\n",
    "        l = iss.replace(\" \",\"\").split(\";\")\n",
    "        for j in l:\n",
    "            data[\"iss_\"+j.lower()][i] = 1\n",
    "            \n",
    "    return data\n",
    "    \n",
    "\n",
    "def discretize_ev_time(data,num):\n",
    "    def threes(x):\n",
    "        if x==0: return 0\n",
    "        if x<0: return x//num\n",
    "        if x>0: return -1*((-1*x)//num)\n",
    "\n",
    "    data[\"grouped_\"+str(num)] = data.ev_time.apply(threes)\n",
    "\n",
    "def add_state_controls(data):\n",
    "    for s in data.state.unique():\n",
    "        name = s.replace(\" \",\"\").lower()\n",
    "        data[\"in_\"+name]=0\n",
    "        data.loc[data.state==s,\"in_\"+name]=1\n",
    "        \n",
    "def add_time_controls(df,pref, days):\n",
    "    def add_zero(i):\n",
    "        s = str(i)\n",
    "        if len(s)==1: s=\"0\"+s\n",
    "        return s\n",
    "\n",
    "    last = 0\n",
    "\n",
    "    for y in [\"2019\",\"2020\"]:\n",
    "        for m in [add_zero(i) for i in range(1,13)]:\n",
    "            for d in days:\n",
    "                thresh = int(y+m+d)\n",
    "                df[pref+\"_\"+str(thresh)]=0\n",
    "                df.loc[(df.date<=thresh) & (df.date>last),pref+\"_\"+str(thresh)] = 1\n",
    "                last = thresh\n",
    "    \n",
    "    to_drop = []\n",
    "    for c in df.columns:\n",
    "        if c[:len(pref)]==pref and 1 not in df[c].unique():\n",
    "            to_drop.append(c)\n",
    "    print(to_drop)\n",
    "    df = df.drop(columns = to_drop)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_diffs(df):\n",
    "    df[\"pct_daily\"] = np.nan\n",
    "    for i in df.index[1:]:\n",
    "        state = df.state[i]\n",
    "        cand = df.cand[i]\n",
    "        title = df.title[i]\n",
    "        \n",
    "        l_state = df.state[i-1]\n",
    "        l_cand = df.cand[i-1]\n",
    "        l_title = df.title[i-1]\n",
    "        \n",
    "        if state==l_state and cand==l_cand and title==l_title:\n",
    "            assert df.ev_time[i]==df.ev_time[i-1]+1\n",
    "            #pct_daily.append((df.poll[i]-df.poll[i-1])/df.poll[i-1])\n",
    "            df[\"pct_daily\"][i]=(df.poll[i]-df.poll[i-1])/df.poll[i-1]\n",
    "\n",
    "def drop_bad(data):\n",
    "    data = data.drop(data.loc[data[\"pct_change\"]==np.inf].index)\n",
    "    data = data.drop(data.loc[data[\"log_change\"]==np.inf].index)\n",
    "    data = data.drop(data.loc[data[\"log_change\"]==-np.inf].index)\n",
    "    data = data.drop(data.loc[data[\"daily_pct\"]==np.inf].index)\n",
    "    data = data.drop(data.loc[data[\"daily_log\"]==np.inf].index)\n",
    "    return data\n",
    "\n",
    "def drop_steyer(data):\n",
    "    data = data.drop(data.loc[data[\"cand\"]==\"tom-steyer\"].index)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "data = drop_steyer(data)\n",
    "\n",
    "discretize_ev_time(data,3)\n",
    "discretize_ev_time(data,4)\n",
    "discretize_ev_time(data,5)\n",
    "discretize_ev_time(data,6)\n",
    "discretize_ev_time(data,7)\n",
    "discretize_ev_time(data,10)\n",
    "discretize_ev_time(data,6)\n",
    "\n",
    "add_state_controls(data)\n",
    "data = drop_bad(data)\n",
    "\n",
    "data = make_issue_cols(data)\n",
    "\n",
    "topic_cols(data,\"grouped_6\")\n",
    "\n",
    "median_split(data, \"airings\")\n",
    "median_split(data, \"cost\")\n",
    "median_split(data, \"poll\")\n",
    "\n",
    "gen_color(data)\n",
    "\n",
    "quantiles(data,n=4,pref=\"f\")\n",
    "quantiles(data,n=5,pref=\"q\")\n",
    "quantiles(data,n=6,pref=\"s\")\n",
    "\n",
    "data = candtime(data)\n",
    "\n",
    "week = [\"00\",\"07\",\"14\",\"21\",\"28\"]\n",
    "data = add_time_controls(data,\"week\",week)\n",
    "\n",
    "week = ['00', '03', '06', '09', '12', '15', '18', '21', '24', '27']\n",
    "data = add_time_controls(data,\"hweek\",week)\n",
    "\n",
    "data.to_csv(\"./formatted_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE PLACEBO DATA\n",
    "date = 20200303\n",
    "\n",
    "st = out.loc[out.state.isin(super_tues)& (out.start<=date)]\n",
    "\n",
    "def mode(x):\n",
    "    a = x.value_counts()\n",
    "    if len(a)==0: print(x)\n",
    "    return a.index[0]\n",
    "\n",
    "def other_states(x):\n",
    "    super_tues = [\"Alabama\",\"Arkansas\",\"California\",\"Colorado\",\"Maine\",\"Massachusettes\",\"Minnesota\",\"North Carolina\",\"Oklahoma\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\"]\n",
    "    super_tues = set(super_tues)\n",
    "    return super_tues-set(x)\n",
    "    \n",
    "\n",
    "st.loc[st.issues.isnull(),\"issues\"]=\"na\"\n",
    "\n",
    "dictdf = st.groupby(by=[\"title\"]).agg({\"candidate\":mode,\n",
    "                                      \"airings\":\"mean\",\n",
    "                                      \"start\":mode,\n",
    "                                      \"end\":mode,\n",
    "                                      \"cost\":\"mean\",\n",
    "                                      \"lookup\":mode,\n",
    "                                      \"issues\":mode})\n",
    "\n",
    "other_states_df = st.groupby(by=\"title\")[\"state\"].apply(other_states)\n",
    "assert len(other_states_df.index)==len(other_states_df.index.unique())\n",
    "os_dict = other_states_df.to_dict()\n",
    "\n",
    "\n",
    "candl = []\n",
    "airingsl = []\n",
    "startl = []\n",
    "endl = []\n",
    "costl = []\n",
    "lookupl = []\n",
    "issuesl = []\n",
    "statel = []\n",
    "titlel = []\n",
    "\n",
    "for i in dictdf.index:\n",
    "    for other_state in os_dict[i]:\n",
    "        candl.append(dictdf.candidate[i])\n",
    "        airingsl.append(dictdf.airings[i])\n",
    "        startl.append(dictdf.start[i])\n",
    "        endl.append(dictdf.end[i])\n",
    "        costl.append(dictdf.cost[i])\n",
    "        lookupl.append(dictdf['lookup'][i])\n",
    "        issuesl.append(dictdf.issues[i])\n",
    "        statel.append(other_state)\n",
    "        titlel.append(i)\n",
    "        \n",
    "placebo_out = pd.DataFrame({'candidate':candl, 'state':statel, 'airings':airingsl, 'start':startl, 'end':endl, 'cost':costl,\n",
    "       'title':titlel, 'lookup':lookupl, 'issues':issuesl})\n",
    "\n",
    "polls = get_poll_diffs()\n",
    "placebo_data = get_data(placebo_out, polls, \"~/Downloads/cdtest/data_placebo_actual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT PLACEBO DATA\n",
    "\n",
    "data = pd.read_csv(\"~/Downloads/cdtest/data_placebo_actual.csv\")\n",
    "#data = pd.read_csv(\"~/Downloads/cdtest/data_home_try_candtime_skip.csv\")\n",
    "\n",
    "data = drop_steyer(data)\n",
    "\n",
    "discretize_ev_time(data,3)\n",
    "discretize_ev_time(data,4)\n",
    "discretize_ev_time(data,5)\n",
    "discretize_ev_time(data,6)\n",
    "discretize_ev_time(data,7)\n",
    "discretize_ev_time(data,10)\n",
    "discretize_ev_time(data,6)\n",
    "#discretize_ev_time(data,7)\n",
    "#discretize_ev_time(data,8)\n",
    "add_state_controls(data)\n",
    "data = drop_bad(data)\n",
    "\n",
    "data = make_issue_cols(data)\n",
    "\n",
    "#topic_cols(data,\"grouped_10\")\n",
    "#topic_cols(data,\"grouped_7\")\n",
    "topic_cols(data,\"grouped_6\")\n",
    "\n",
    "\n",
    "median_split(data, \"airings\")\n",
    "median_split(data, \"cost\")\n",
    "median_split(data, \"poll\")\n",
    "\n",
    "gen_color(data)\n",
    "\n",
    "#lb(data)\n",
    "quantiles(data,n=4,pref=\"f\")\n",
    "quantiles(data,n=5,pref=\"q\")\n",
    "quantiles(data,n=6,pref=\"s\")\n",
    "\n",
    "data = candtime(data)\n",
    "#data = candstate(data)\n",
    "\n",
    "#data.loc[data.ev_time<=0,\"polla\"]=0\n",
    "\n",
    "\n",
    "week = [\"00\",\"07\",\"14\",\"21\",\"28\"]\n",
    "data = add_time_controls(data,\"week\",week)\n",
    "\n",
    "week = ['00', '03', '06', '09', '12', '15', '18', '21', '24', '27']\n",
    "data = add_time_controls(data,\"hweek\",week)\n",
    "\n",
    "data.to_csv(\"./placebo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE REAL DATA FOR PLACEBO TEST\n",
    "date = 20200303\n",
    "\n",
    "non_placebo = out.loc[out.state.isin(super_tues)& (out.start<=date)].copy()\n",
    "\n",
    "polls = get_poll_diffs()\n",
    "nonplacebo_data = get_data(non_placebo, polls, \"~/Downloads/cdtest/data_nonplacebo_actual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT REAL DATA FOR PLACEBO TEST\n",
    "\n",
    "data = pd.read_csv(\"~/Downloads/cdtest/data_nonplacebo_actual.csv\")\n",
    "\n",
    "data = drop_steyer(data)\n",
    "\n",
    "discretize_ev_time(data,3)\n",
    "discretize_ev_time(data,4)\n",
    "discretize_ev_time(data,5)\n",
    "discretize_ev_time(data,6)\n",
    "discretize_ev_time(data,7)\n",
    "discretize_ev_time(data,10)\n",
    "discretize_ev_time(data,6)\n",
    "add_state_controls(data)\n",
    "data = drop_bad(data)\n",
    "\n",
    "data = make_issue_cols(data)\n",
    "\n",
    "topic_cols(data,\"grouped_6\")\n",
    "\n",
    "\n",
    "median_split(data, \"airings\")\n",
    "median_split(data, \"cost\")\n",
    "median_split(data, \"poll\")\n",
    "\n",
    "gen_color(data)\n",
    "\n",
    "quantiles(data,n=4,pref=\"f\")\n",
    "quantiles(data,n=5,pref=\"q\")\n",
    "quantiles(data,n=6,pref=\"s\")\n",
    "\n",
    "data = candtime(data)\n",
    "\n",
    "week = [\"00\",\"07\",\"14\",\"21\",\"28\"]\n",
    "data = add_time_controls(data,\"week\",week)\n",
    "\n",
    "week = ['00', '03', '06', '09', '12', '15', '18', '21', '24', '27']\n",
    "data = add_time_controls(data,\"hweek\",week)\n",
    "\n",
    "data.to_csv(\"./real_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
